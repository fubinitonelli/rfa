%!TEX root = ../main.tex
\subsubsection{Linear Bounded Operators in Hilbert Spaces}
Now we will generalize one of the most powerful theorem of Linear Algebra to infinite dimensional case. The crucial element we have to build is about how to calculate the norm of an operator. In case of bounded operators we can use a bilinear form, the scalar product.

\begin{prop}
	Let $(H,\sca{\cdot, \cdot} )$ be a separable Hilbert space, and $T \in \Bc(H)$.\\
	Then we have:
	$$
	\norm{T}_{\Bc(H)} 
	= \sup_{\norm{x}=1, \ \norm{y}=1} 
	\abs{\sca{Tx,y}}
	.
	$$
\end{prop}
\begin{proof}
	Observe that (see the CS inequality \vref{prop-cs-hilbert})
	$$
	\abs{\sca{Tx,y}}
	\leq \norm{Tx}\norm{y}
	\leq \norm{T}\norm{x}\norm{y}
	\implies 
	\sup_{\norm{y}=\norm{x}=1} \abs{\sca{Tx,y}} \leq \norm{T}
	.
	$$
	On the other hand, taking $y=\frac{Tx}{\norm{Tx}}$, with $Tx \neq 0$, we have the equality:
	$$
		\sup_{\norm{y}=\norm{x}=1} \abs{\sca{Tx,y}}
		\geq \sup_{\norm{x}=1} \abs{\sca{Tx,\frac{Tx}{\norm{Tx}}}}
		= \sup_{\norm{x}=1} \frac{\norm{Tx}^2}{\norm{Tx}}
		= \norm{T}
	$$
\end{proof}

Let $\{v_n\}_{n\in\NN}$ be an orthonormal basis in $(H, \sca{\cdot, \cdot})$, separable Hilbert space.\\
Then let 
$$
x 
= \sum_{n \in \NN} x_n v_n
.
$$
The sequence of partial sums converges in $H$ to $x$, and $T$ is continuous, thus 
$$Tx 
= \sum_{n \in \NN} x_n T v_n
.
$$
But in turn $Tv_n = \sum_{m \in \NN} \sca{Tv_n, v_m} v_m$.\\
Set $T_{nm} = \sca{Tv_n,v_m}$ to have $Tx = \sum_{n \in \NN}\sum_{m \in \NN} x_nT_{nm}v_m$.
	
Therefore, being $y = \sum_{n \in \NN} y_n v_n$, we have $\sca{Tx,y} = \sum_{n,m \in \NN} T_{nm} x_n y_m$, and:
$$
\norm{T}_{\Bc(H)} 
= \sup_{\substack{\norm{\{x_n\}}_{l^2}=1 \\
	\norm{\{y_n\}}_{l^2}=1}}
\abs{\sum T_{nm} x_n y_m}
.$$
Where $T_{nm}$ are the Fourier coefficients of $T$.
	
\begin{defn}
	Let $(H,\sca{\cdot, \cdot} )$ be a separable Hilbert space.\\
	We say that $T \in \Bc(H)$ is \emph{symmetric} if 
	$$
	\sca{Tx,y}  
	= \sca{x,Ty}  
	\quad \forall x,y \in H
	.
	$$
\end{defn}

Observe that $T$ is symmetric if and only if $T_{nm}= T_{mn}$.

\begin{prop}
	If $T \in \Bc(H)$ is symmetric, then $\norm{T}_{\Bc(H)} = \sup_{\norm{x}=1}|\sca{Tx,x} |$.
\end{prop}

\begin{proof}
	Set 
	$$
	c 
	= \sup_{\norm x =1}|\sca{Tx,x} |
	;
	$$ 
	it is easy to realize that (see the CS inequality \vref{prop-cs-hilbert}) $c \leq \norm{T}_{\Bc(H)}$.\\
	Vice-versa we have, for any $x,y \in H$:
	\begin{align*}
		4\sca{Tx,y}
		&= \sca{ T(x+y), x+y}  - \sca{T(x-y), x-y} \\
		&\leq c(\norm{x+y}^2+\norm{x-y}^2)\\
		& = 2c(\norm{x}^2+\norm{y}^2)
	\end{align*}
	where at the last equality we have applied the parallelogram identity. 
	
	Suppose now $Tx \neq 0$ (otherwise the proof is trivial) and take 
	$$
	y 
	= \frac{\norm{x}}{\norm{Tx}}Tx
	.
	$$
	Then we have:
	$$
	\norm x \norm{Tx} 
	\leq c \norm{x}^2
	$$ 
	which implies
	$$
	\norm{Tx} 
	\leq c \norm{x}
	$$
	and then
	$$ 
	\norm{T}_{\Bc(H)} 
	\leq c
	.
	$$
	Therefore $\norm{T}_{\Bc(H)}=c$ and this concludes the proof.
\end{proof}


\begin{exam}
	Let $V \subset H$ be a closed subspace.
	The projector $P_V \in \Bc(H)$ is symmetric, indeed:
	\begin{align*}
		\sca{P_Vx, y}
		&= \sca{P_Vx, P_Vy+ P_{V^\perp}y}  \\
		&= \sca{P_Vx, P_Vy} \\
		&= \sca{P_V x+ P_{V^\perp} x, P_V y} \\ 
		&= \sca{x, P_V y}.
	\end{align*}
	Moreover, if $V$ is finite dimensional, notice that $P_V$ is compact and symmetric.
\end{exam}
\begin{exam}
	Consider the space $H=L^2(\Omega)$ where $\Omega \in \Lc(\RR^N)$.\\
	Let $G\in L^2(\Omega \times \Omega)$, and $K_G$ be the associated Hilbert--Schmidt operator: 
	$$
	K_G u(t) 
	= \int_0^1 G(t,s) u(s) \, \dlam
	.
	$$
	We already know that $K_G \in \Kc(H)$. You can prove that: $K_{G}$ is symmetric if and only if $G(t,s) = G(s,t)$ a.e. in $\Omega \times \Omega$.
\end{exam}

\paragraph{Eigenvalues and eigenvectors}

\begin{defn}
	Let $T \in \Bc(H)$.\\
	A real number $\lambda \in \RR$ is an \emph{eigenvalue} for $T$ if there exists $u \in H$, such that $u \neq 0$ and:
	$$
	Tu 
	= \lambda u
	.
	$$
	In this case $u$ is the \emph{eigenvector} of $T$ associated with $\lambda$. \\
	The linear subspace generated by all the eigenvectors associated with $\lambda$ is called \emph{eigenspace} of $\lambda$ and is denoted with $E_\lambda$.
\end{defn}

\begin{prop}
	Any eigenspace $E_\lambda$ is closed.
\end{prop}
You can prove this result. Do it!\footnote{Hint: use the continuity of $T$.}

Moreover for any eigenvalue and its eigenvector we have
$$
\frac{\norm{Tu}}{u} 
= |\lambda|
$$
 and 
$$
|\lambda|
\leq \norm{T}_{\Bc(H)}
.
$$

\begin{defn}
	The dimension of the eigenspace associated to $\lambda$, namely $\dim E_\lambda$, is called \emph{geometric multiplicity} of $\lambda$.
\end{defn}
Notice that in Hilbert spaces there is no such thing as algebraic multiplicity of an eigenvalue.

\begin{prop}
	Let $T \in \Bc(H)$ symmetric.\\
	Given two distinct eigenvalues of $T$, their associated eigenvectors are mutually orthogonal, and therefore are linearly independent.\\
	Moreover we have also that the eigenvalues of $T$ are at most countable.
\end{prop}

\begin{proof}
	Let $u_1$ and $u_2$ be the eigenvector associated with $\lambda_1$ and $\lambda_2$, where $\lambda_1\neq 0$ (otherwise just swap the indexes).\\
	Then we have:
	$$
	\sca{u_1,u_2} 
	=\frac{1}{\lambda_1}\sca{Tu_1,u_2} 
	= \frac{1}{\lambda_1}\sca{u_1, T u_2} 
	= \frac{\lambda_2}{\lambda_1}\sca{u_1, u_2}
	.
	$$
	As $\frac{\lambda_2}{\lambda_1} \neq 0$, we have that necessary $\sca{u_1, u_2} =0$.

	Finally, as $H$ is separable, the eigenvalues are at most countable.% \todo{qui ci sarebbe da spiegare meglio il perché}
\end{proof}

\paragraph{Compactness}
\begin{prop}
	\label{prop-pm-norm-eigenvalue}
	Let $K \in \Kc(H)$ be symmetric.\\
	Then $\norm{K}_{\Bc(H)}$ or $-\norm{K}_{\Bc(H)}$ is an eigenvalue of $K$.
\end{prop}

\begin{proof}
	First, observe that if $\norm{K}_{\Bc(H)}=0$ then the thesis is trivial.\\
	Consider $ c = \norm{K}_{\Bc(H)}$ and suppose $c > 0$
	We know that $c = \sup_{\norm{x}=1}|\sca{Kx,x} |$ and thus, by definition, there exists a maximizing sequence $\{x_n\}_{n\in\NN} \subset H$ such that $\norm{x_n}=1$ and 
	$$
	|\sca{Kx_n,x_n} | 
	\to c
	.
	$$
	
	Since $\{x_n\}$ is bounded and $H$ is reflexive there exist $\{x_{n_h}\}_{h \in \NN}$ such that $x_{n_h} \wto x$ and $\norm{x} < 1$ (see Eberlein--Šmulian theorem \vref{theo-eberlin-smulian}).\\
	Moreover, via weak-strong continuity of $K$ we have $Kx_{n_h} \to Kx$ (see theorem \vref{theo-compact-charact}).\\
	Hence 
	$$
	|\sca{Kx_{n_h}, x_{n_h}} | 
	\to |\sca{Kx,x} |
	= c 
	\neq 0
	,$$
	and $x \neq 0$.
	
	Suppose, without loss of generality, $c = \sca{Kx,x}$. Observe that:
	\begin{align*}
		\norm{Kx-cx}^2
		&=\norm{Kx}^2+c^2\norm{x}^2-2c\sca{Kx,x} \\
		&= \norm{Kx}^2 + c^2\norm{x}^2 - 2c^2\\
		& \leq 2c^2\norm{x}^2 - 2 c^2 \\
		&\leq 0
	\end{align*}
	So $Kx = cx$, that is $x$ is the eigenvector associated with $c$.
\end{proof}

Therefore, if $K \in \Kc(H)$ symmetric, its norm can be equivalently defined as follows:
$$
\norm{K}_{\Bc(H)}
= \max \{|\lambda| : \lambda \text{ is an eigenvalue of }K\}
.
$$

\begin{prop}
	\label{prop-eigenspace-finite-dim}
	Let $K \in \Kc(H)$ and $\lambda \neq 0$ be an eigenvalue of $K$. \\
	Then the geometric multiplicity of $\lambda$ is finite, namely:
	$$
	\dim E_\lambda
	\leq \infty
	.
	$$
\end{prop}

\begin{proof}
	Suppose by contradiction that the dimension is infinite: let $\{v_n\}_{n\in\NN}$ be an orthonormal basis of $E_\lambda$. \\ 
	Then $Kv_n=\lambda v_n \ \forall n \in \NN$, $v_n \wto 0$ and $\norm{v_n}=1$ for all $n \in \NN$. \\
	Thus $Kv_n \to 0$ but $v_n \not \to 0$, which is absurd.
\end{proof}

\paragraph{The spectrum}
\begin{defn}
	Let $T \in \Bc(H)$ be symmetric.\\ 
	Define the \emph{spectrum} of $T$ as:
	$$
	\sigma(T) 
	\coloneqq \{\lambda \in \RR : \lambda \text{ is an eigenvalue of } T \}
	.$$
	Moreover define the \emph{resolvent} of $T$:
	$$
	\Rc(T) 
	\coloneqq \sigma(T)\comp
	.
	$$
\end{defn}

It is easy to see that if $\mu \in \Rc(K)$ then $\Ker(\mu I-K) = \{0\}$ and so is injective.\\
Note also that if $T \in \Kc(H)$ is symmetric then $\sigma(T) \neq 0$.

\begin{theo}[spectral theorem]\label{theo-spect}
	Let $K \in \Kc(H)$ be symmetric. Then:
	\begin{itemize}
		\item either $\sigma(K)$ is finite,
		\item or $\sigma(K)$ is a sequence $\{ \lambda_n\}_{n \in \NN}$ such that $\lambda_n \to 0$.
	\end{itemize}
	In both cases $0$ can be either an eigenvalue or not.\\%and is multiplicity can be finite or infinite. zero may or may not belong to $\sigma(K)$, and if $0 \in \sigma(K)$ then its multiplicity can be either finite or infinite.
	Moreover, we can always choose the eigenvectors in such a way that they form an orthonormal basis on $H$.
\end{theo}

If $H$ has infinite dimension and $\sigma(T)$ is finite the $0$ is necessarily an eigenvalue and $E_0$ has infinite dimension.
Otherwise if $\sigma(T)$ is a sequence and $0$ is an eigenvalue then $E_0$ can have either finite or infinite dimension. 

\begin{proof}
	Let $\lambda_1$ be an eigenvalue such that (see \vref{prop-pm-norm-eigenvalue}) $|\lambda_1|= \norm{T}_{\Bc(H)}$, and $E_{\lambda_1}$ be its eigenspace.
	
	If $\lambda_1 = 0$, then $\Ker(T) = H$ and $T \equiv 0$. Therefore $\sigma(T) = {0}$, any orthonormal basis of $H$ is a basis of the eigenspace, and the theorem is proven.
	
	If $\lambda_1 \neq 0$, we know that $E_{\lambda_1}$ has finite dimension and setting $H_1 = E_{\lambda_1}^\perp$ we have:
	$$
		H
		= E_{\lambda_1} \oplus E_{\lambda_1}^\perp
		.
	$$
	We have
	$$
		\sca{Ty, x}
		= \sca{y, Tx}
		= \sca{y, \lambda_1x}
		= 0
		\quad \forall y \in H, \ x \in E_{\lambda_1}
	$$
	and so $T(H_1) \subset H_1$ (prove it).
	
	Consider now $T_1 = T|_{H_1}\in \Kc(H_1)$: if $\norm{T_1}_{\Bc(H_1)} = 0$ we have finished, otherwise we consider the non-zero eigenvalue $\lambda_2$ such that:
	$$
		\abs{\lambda_2}
		= \norm{T_1}_{\Bc(H_1)}
		\leq \abs{\lambda_1}
		= \norm{T}_{B(H)} 
	$$
	where $\lambda_2$ has finite geometric multiplicity.
	
	Now set $H_2 = E_{\lambda_2}^\perp$: we have
	$$
		H_1
		= E_{\lambda_2} \oplus H_2
		.
	$$
	Consider $T_2 = T_1|_{H_2}$: either we find that the norm of the restricted operator is zero after a finite number of steps, and the proof is finished, or we can construct a sequence of non-zero eigenvalues $\{\lambda_n\}_{n \in \NN_0}$ such that
	$$
		\abs{\lambda_{n+1}} 
		\leq \abs{\lambda_n}
		\quad \forall n \in \NN_0
		.
	$$
	To conclude the proof of this case, first we have to show that $\lambda_n \to 0$.
	
	Suppose by contradiction that
	$$
		\Lambda 
		= \inf_{n\in \NN_0}\abs{\lambda_n} 
		> 0
		.
	$$
	We want it to be $0$. For each $E_{\lambda_n}$ consider an orthonormal basis of eigenvectors and denote such whole sequence with $\{w_k\}_{k \in\NN_0}$, obviously it is bounded and we have $\norm{w_k}=1$. \\
	As $H$ is reflexive there exists (see \vref{prop-coro-BA}) a subsequence $\{w_{k_h}\}$ such that $w_{k_h} \wto w$.\\
	Then
	$$
		Tw_{k_h}
		= \lambda_{k_h}w_{k_h}
	$$
	converges strongly to $Tw$ (each eigenvalue is counted with is geometric multiplicity).\\
	Therefore:
	$$
		\norm{ \lambda_{k_h}w_{k_h} - \lambda_{k_{h'}}w_{k_{h'}} }^2 
		= |\lambda_{k_h}|^2+|\lambda_{k_{h'}}|^2
		\geq 2\Lambda^2
		,
	$$
	but $\norm{Tw_{k_h}-Tw_{k_{h'}}}^2 \to 0$ as $h,h' \to \infty$: this is a contradiction because it implies $\Lambda = 0$.\\
	So $\lambda_n \to 0$ as $n$ goes to $\infty$.
	
	Observe now that if $x \in H_n$ for all $n \in \NN_0$ then 
	$$
		\sca{x, w_k}
		= 0
		\quad \forall k \in \NN_0
	$$
	and
	$$ 
		\norm{Tx} 
		= \norm{T_nx} 
		\leq \norm{T_n}_{\Bc(H_n)}\norm{x}
		= \abs{\lambda_n}\norm{x}
		\quad \forall n \in \NN_0
		,
	$$
	letting $n$ go to $\infty$ we find $Tx=0$, namely $x \in \Ker(T)$.\\
	
	Then, either $\Ker(K) = \{0\}$, and zero is not an eigenvalue, and the sequence $\{w_k\}_{k \in \NN_0}$ is an orthonormal basis for $H$, or $\Ker(K) \neq \{0\}$, and zero is an eigenvalue, with finite or infinite multiplicity, and we have to add an orthonormal basis of $\Ker(T)$ in order to have an orthonormal basis for $H$.
\end{proof}

\paragraph{Consequences of the spectral theorem} This result has two immediate and important consequences: the \emph{diagonalization} and the \emph{approximation property}. \\

\begin{prop}[diagonalization]
	Let $(H,\sca{\cdot, \cdot} )$ be a separable Hilbert space, and $T \in \Kc(H)$ be symmetric.
	
	If $\dim_\perp H = N$, then the spectral theorem \vref{theo-spect} coincides with the homonymous theorem of Linear Algebra: $T$ can be identified as a Matrix once a basis is fixed.
	
	If $\dim_\perp H = \aleph_0$, let $\{w_n\}_{n \in \NN}$ be an orthonormal basis of eigenvectors of $T$, then $t_{n,m} \coloneqq \sca{K w_n, w_n} = \lambda_n \delta_{n,m}$, where each $\lambda_n$ is counted with its multiplicity, we have
	$$
		Tx 
		= \sum_{n\in\NN} \lambda_n x_n w_n
		.
	$$
\end{prop}

The \emph{approximation property} \todo{maybe this is also a proposition} is the following: consider $(H,\sca{\cdot, \cdot} )$ separable Hilbert space, and $T \in \Kc(H)$ be symmetric.\\
Suppose also $\dim_\perp H = \aleph_0$ and consider $\{w_n\}_{n \in \NN}$ as an orthonormal basis of eigenvectors of $T$. then we know that: 
$$
	Tx 
	= \sum_{n\in\NN} \lambda_n x_n w_n
	.
$$
Therefore by setting $T_N x = \sum_{n=1}^N \lambda_n x_n w_n$ we have:
\begin{align*}
	\norm{Tx-T_N x}^2
	&= \sum_{n=N}^{+\infty} |\sca{(k-k_n)x, w_n})|^2 \\
	&= \sum_{n=N+1}^{+\infty} (\lambda_n x_n \sca{w_n, w_n})^2 \\
	&\le \left( \sup_{n \ge N + 1} \lambda_n^2 \right) \sum_{n=N+1}^{+\infty} x_n^2
	& \text{($\{\lambda_n\}$ is decreasing)} \\
	&\le \lambda_{N+1}^2 \sum_{n=0}^{+\infty} x_n^2
	=\lambda_{N+1}^2 \norm{x},
\end{align*}
so that
$$ 
	\norm{T-T_N}_{\Bc(H)} 
	\leq \lambda_{N+1}^2 
	\to 0
	\text{ as } N \to +\infty
	.
$$

\paragraph{Fredholm's alternative} We recall that in Banach spaces we stated without proving corollary \vref{coro-fredholm-b-spaces}. In this scenario, namely Hilbert Spaces, we can give a similar result and a proof.

\begin{theo}
	\label{theo-fredholm-h-spaces}
	Let $(H,\sca{\cdot, \cdot} )$ be a separable Hilbert space, and $T \in \Kc(H)$ be symmetric.\\
	Let $\mu \in \RR, \mu \neq 0$.\\
	Then, either for any $y \in H$ there exists a unique $x \in H$ such that 
	$$
		\mu x - Tx 
		= y
		.
	$$
	or $\mu$ is an eigenvalue of $T$.
	
	Moreover 
	$$
		\Ker (\mu I - T)^\perp 
		= \Im (\mu = - T)
		.
	$$
\end{theo}

%Via Fredholm's alternative, either $\mu I-K$ is a bijection or $\Ker(\mu I - K)$ has positive finite dimension $m_0$\\
%In the latter case, $\mu$ is an eigenvalue, and moreover if $y \in \Ker(\mu I - K)^\perp$ then $\mu x - k x = y$ has infinite solutions, otherwise it does not have any solutions.
This implies that if $\mu \neq 0$ then
$$
	\Ker(\mu I - T) \ \text{is finite dimensional}
$$
and
$$
	\Ker(\mu I - T) =\{0\} \iff \Im (\mu I - T) = H.
$$
The first one is because if $\mu$ is not an eigenvalue, we are in the first alternative, then we can choose $y=0$ and there will be one and only one $x$ such that $Tx-\mu x=0$, namely only one element in the Kernel: $\Ker(\mu I-T)=\{0\}$. If instead $\mu$ is an eigenvalue, if we consider an element of the Kernel, $x\in \Ker(\mu I -T)$, this element is the eigenvector associated with $\mu$, and then $\Ker(\mu I-T)=E_{\mu}$, with $\mu\neq 0$. But then (see \vref{prop-eigenspace-finite-dim}) this space must be finite dimensional.

The second one is entailed by the `Moreover' part of the theorem.

\begin{proof}
	If $\dim_\perp H \neq \aleph_0$ then the thesis follows from Fredholm's alternative (this would be a theorem of Linear Algebra).\\
	
	Let $\{w_n\}_{n \in \NN}$ be an orthonormal basis of eigenvectors of $T$ and $\{\lambda_n\}_{n \in \NN}$ be the sequence of corresponding eigenvalues (each counted with its multiplicity). We have:
	$$
		x
		=\sum_{n \in \NN}x_n w_n 
		\qquad 
		Tx 
		= \sum_{n\in\NN} \lambda_n \lambda_n w_n 
		\qquad 
		y 
		= \sum_{n \in \NN} y_n w_n
		;
	$$
	then
	$$ 
		\mu x - Tx 
		=\sum_{n \in\NN}(\mu - \lambda_n) x_n w_n
		.
	$$
	
	If $y \in H$, to find a solution to $\mu x - Tx = y$ is equivalent to solve the system of infinite equations 
	$$
		(\mu- \lambda_n) x_n
		= y_n
		\quad
		n \in \NN_0
		.
	$$
	
	If $\mu \neq \lambda_n$ for any $n \in \NN_0$ then the previous system is uniquely solvable by taking $x_n = (\mu - \lambda_n)^{-1}y_n$.
	
	Alternatively, if $\mu = \lambda$ for some $n \in \NN_0$, remember first that $\lambda_n$ is counted with its multiplicity $m$, that is:
	$$
		\lambda_n 
		= \lambda_{n+1} 
		= \cdots
		= \lambda_{n+m}.
	$$
	The key idea here is that:
	\begin{align*}
		\Ker(\mu I-T) &= \{x:\mu x - Tx = 0\}\\
					&= \{ x: \mu x = Tx \}\\
					&= \{\text{eigenvectors associated with }\mu\}
	\end{align*}
	Then we may have no solutions if $ y \notin \Ker (\mu I - T)^\perp$, i.e. if $y$ is not orthogonal to all the eigenvectors associated with $\mu$.\\
	Otherwise, there are $m$ independent solutions.\\
	We also conclude that the equation is solvable if and only if $y \in \Ker (\mu I - T)^\perp$, namely if $y_j,j=n,\ldots,n+m$ are all equal to zero, that is, $y$ orthogonal to all the eigenvectors associated with $\mu$. In this latter case, we obviously have infinite solutions.
\end{proof}

From the previous theorem we have the following result:
\begin{prop}
	Let $(H,\sca{\cdot, \cdot} )$ be a separable Hilbert space, and $T \in \Kc(H)$ be symmetric.\\
	If $|\mu| \leq \norm{T}_{\Bc(H)}$ then $\mu$ can be an eigenvalue of $T$.\\
	If $|\mu| > \norm{T}_{\Bc(H)}$ then $\mu$ is not an eigenvalue of $T$ and the equation $\mu x - T x = y$ is uniquely solvable for all $y \in H$.
\end{prop}

\begin{exam}
	Consider $H= L^2(\Omega)$, with $\Omega \in \Lc(\RR^N)$ and consider:
	$$
	(K_G u)(x) 
	= \int_\Omega G(t,s) u(s) \, \ds
	$$
	with $G \in L^2(\Omega \times \Omega)$ such that $G(t,s)=G(s,t)$ almost everywhere in $\Omega \times \Omega$: we deduce that $K_G \in \Kc(H)$ and is symmetric.
	
	Therefore, if $v \in H$ and we want to check the solvability of the equation
	$$
	\mu u - K_G u
	= v
	$$
	for some $\mu \neq 0$ which is an eigenvalue for $K_G$.\\
	Then we need to check the following conditions
	$$
	\int_\Omega v w_j \, \dt 
	= 0 
	\quad 
	j = 1, \ldots, m
	$$
	where $\{w_1, \ldots , w_m\}$ is an orthonormal basis of $\Ker (\mu I - K_G)$.	
\end{exam}


\begin{exam} This example complete the example of application of Lax--Milgram lemma \vref{app-lax-milgram}.
	Consider a bilinear form $a: V_0 \times V_0 \to \RR$ defined by:
	$$
	a(u,v)
	= \int_a^b [(\alpha(x)u'(x) 
	+ \beta(x)u(x))v'(x) 
	+ \gamma(x)u(x)v(x)]\,\dx
	$$
	and assume  $\alpha, \, \gamma \in L^\infty((a,b))$, like the following:
	$$
	\alpha_0
	= \inf\limits_{x\in[a,b]} \alpha(x)
	> 0
	\text{ and }
	\gamma(x) 
	\geq 0
	\text{ for almost any }
	x \in [a,b]
	.
	$$
	Then $a(\cdot, \cdot)$ is a symmetric continuous and coercive bilinear form.\\
	Moreover, its induced norm is equivalent to $\norm{\cdot}_0$.
	
	By Lax--Milgram (see theorem \vref{theo-lax-milgram}) we have that for any $f \in L^2((a,b))$
	there is a unique $u \in V_0$ such that:
	$$
	a(u,v) 
	= \sca{f,v} 
	\coloneqq \int_a^b f(x) v(x) \, \dx 
	\quad \forall v \in V_0
	.
	$$
	
	Thus linear operator $K: L^2((a,b)) \to L^2((a,b))$ defined by 
	$$
	Kf
	= u \in V_0
	$$
	is compact.
	
	Notice that $K$ is also symmetric, indeed, we have:
	$$
	a(Kf,v)
	=
	\sca{f, v},
	\quad
	a(Kg, v)
	= \sca{g, v}
	\quad
	\forall v \in V_0
	.
	$$
	
	If we choose $v = Jg$ in the first identity and $v = J f$ in the second one, we get:
	$$
	a(Kf, Kg) 
	= \sca{f, Kg}
	,
	\quad
	a(Kg, Kf)
	= \sca{g , Kf}
	$$
	but 
	$$
	a(Kf, Kg) 
	= a(Kg, Kf)
	$$
	so that
	$$
	\sca{f, Kg} 
	= \sca{g, Kf}
	.
	$$
	
	Thanks to the spectral theorem and recalling that $K$ is injective since $\Ker K = \{0\}$, we can say that $K$ has a sequence of non-zero eigenvalues $\{\lambda_n\}_{n\in \NN}$ such that $\lambda_n \to 0$.
	
	Moreover we can construct an orthonormal basis of $L^2((a,b))$ which consists of eigenfunctions $\{u_n\}_{n\in \NN}$, namely
	$$
	Ku_n 
	= \lambda_n u_n
	\text{ implies }
	a(u_n, v)
	= \mu_n \sca{u_n, v}
	\quad 
	\forall v \in V_0
	$$
	where $\mu_n = \lambda_n^{-1}$.
	Notice that these eigenfunctions form an orthogonal basis of $V_0$ as well.	
\end{exam}

As an exercise you can calculate the eigenvalues and eigenfunctions of $K$ in case of $(a,b)=(0, 2\pi)$ and $\alpha = 1$ and $\gamma = 0$.


\paragraph{Examples on the spectra of non-compact linear bounded operators}
If $T \in \Kc(H)$ is symmetric, then $\sigma(T)$ is always non-empty and countable. This is not always true if compactness fails.

\begin{exam}
	The identity operator $I:H \to H$ is symmetric and non-compact if $H$ has finite dimension. Notice that its spectrum is ${1}$ and its eigenspace is the whole $H$.
\end{exam}

\begin{exam}
	Consider $H = L^2((-1,1))$ and consider
	$$
	(Tf)(t)
	= tf(t)
	\text { a.e. in (-1,1)}
	.
	$$
	Then $T \in \Bc(H)$ and is symmetric, but not compact. \\
	Suppose $\exists \, f \not \equiv 0$ and $\lambda \in \RR$ such that $Tf = \lambda f$ for almost any $t \in [-1,1]$. Then $tf(t) = \lambda f(t)$: it must be $f \equiv 0$, and $\sigma(T) = \varnothing$.
\end{exam}

\begin{exam}
	Consider $H=l^2$ and let:
	\begin{align*}
		T_R(x) 
		&\coloneqq \{0, x_1, x_2, \ldots, x_n, \ldots \} 
		\quad & \forall x
		=\{x_1, x_2, \ldots, x_n, \ldots \, \}&\in H
		, \\
		T_L(x) 
		&\coloneqq \{x_2, x_3, x_4, \ldots, x_n, \ldots \} 
		\quad & \forall x
		=\{x_1, x_2, \ldots, x_n, \ldots \, \}&\in H
		.
	\end{align*}
	It's easy to prove that $T_R, T_L \in \Bc(H)$ but they are not neither compact nor symmetric.
	
	It's easy to check that $\sigma(T_R) = \varnothing$.
	
	Concerning $T_L$, from $T_Lx = \lambda x$ we deduce:
	$$
	\lambda x_1
	= x_2
	,
	\lambda x_2
	= x_3
	,
	\ldots
	,
	\lambda x_n
	= x_{n+1}
	,
	\ldots
	$$
	for all $n \in \NN_0$.\\
	Then $x= \{1, \lambda, \lambda^2, \ldots, \lambda^{n+1}, \ldots \}$ is an eigenvalue for $T_L$ if and only if $x\in l^2$, that is if and only if $\abs{\lambda} < 1$.
	Thus
	$$
	\sigma(T_L)
	= (-1, 1)
	.
	$$
\end{exam}

\begin{exam}
	Consider $H=l^2$. Let . Suppose $\exists \, x \neq 0$ such that $T_rx = \lambda x$ for some $\lambda \in \RR$. Then $0 = \lambda x_1$, $x_1 = \lambda x_2$, and so on. If $\lambda = 0$, then $x = 0$, and $\lambda$ is not an eigenvector. If $\lambda \neq 0$, then it must be $x_1 = 0$, $x_2 = 0$, and so on; then again $x = 0$. Therefore $T_r$ has no eigenvalues: $\sigma(T_r) = \varnothing$.
\end{exam}

\begin{exam}
	Consider again $H= l^2$, and define $T_l(\{x_n\}_{n \in \NN}) \coloneqq \{x_2, x_3, \ldots, x_n, \ldots \}$.
	Suppose $\exists \, x \neq 0$ such that $T_rx = \lambda x$ for some $\lambda \in \RR$. Then $\lambda x_2= x_1$, $\lambda x_3= x_2$, and in general $\lambda x_{n+1} = x_n$. \\
	If $\lambda = 0$, then $(x_1, 0, \ldots, 0, \ldots, 0)$ is an eigenvector for any $x_1 \neq 0$. Therefore $\lambda =0$ is an eigenvalue.\\
	If $\lambda \neq 0$, we have $x_{n+1} = \lambda^n x_1$. Moreover:
	$$x=(1,\lambda, \lambda^2, \ldots, \lambda^n, \ldots) \in l^2
	\iff \sum_{n \in \NN}\lambda^{2n} < +\infty \iff |\lambda| < 1$$
	Therefore $\sigma(T_l)=(-1,1)$: the spectrum is continuous.
\end{exam}
